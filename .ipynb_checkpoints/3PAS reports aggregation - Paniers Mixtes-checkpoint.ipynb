{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns #pour faire des graph dans la bonne couleur etc.. par default\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Upload datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Define products to be taken into account for credited conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">/!\\ Which products do you want to take into account????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://stackoverflow.com/questions/12096252/use-a-list-of-values-to-select-rows-from-a-pandas-dataframe\n",
    "#gamme_prod = ['DN', 'DI', 'PD', 'TI', 'TN']\n",
    "gamme_prod = ['DN', 'DI', 'PD', 'TI', 'TN','Mixte']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Name of the files to be uploaded\n",
    "\n",
    "> These should be hosted in the root folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#file_quanti \n",
    "adServerFile = 'Report_Quantcast_mobilite_Standard_v1_M88Z5cUHryFJpRP_AA1S.xlsx'\n",
    "#file_quali \n",
    "detailedFile = 'Report_Quantcast_mobilite_conversion_view_PNJjl0461vpIzpMgHrA7.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first file to be uploaded details of products part of each conversion\n",
    "detailedConversions = pd.read_csv(detailedFile, dtype=object)\n",
    "\n",
    "#We need to update the date format and strip hours\n",
    "#http://stackoverflow.com/questions/26387986/strip-time-from-an-object-date-in-pandas\n",
    "detailedConversions['conversion_date'] = pd.to_datetime(detailedConversions['Conversion date-hour'])\n",
    "detailedConversions['conversion_date'] = detailedConversions['conversion_date'].apply(lambda x:x.date().strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#detailedConversions details products within each orders\n",
    "#check what's in detailedConversions\n",
    "#detailedConversions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#then upload the second file. this is the regular 3PAS files with every conversions to which we contributed. \n",
    "xls_file = pd.ExcelFile(adServerFile)\n",
    "adServerTable = xls_file.parse('DataView')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#adServerTable credits each order to a vendor\n",
    "# /!\\ We want to had details of orders containing products for which we are credited /!\\\n",
    "#check what's in adServerTable\n",
    "#adServerTable.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create functio that will be used to create matching key by concatenating several columns\n",
    "#http://stackoverflow.com/questions/23444858/concatenate-column-values-in-pandas-dataframe-with-nan-values\n",
    "def concat(*args):\n",
    "    strs = [str(arg) for arg in args if not pd.isnull(arg)]\n",
    "    return '_'.join(strs) if strs else np.nan\n",
    "\n",
    "np_concat = np.vectorize(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We need to define the key to join both file. \n",
    "#first 3PAS report Key\n",
    "adServerTable['key'] = np_concat(adServerTable['Date'], adServerTable['Site/Offer ID'], adServerTable['Insertion ID'], adServerTable['Creative ID'])\n",
    "#QA the created key\n",
    "\n",
    "#adServerTable[['Date','Site/Offer ID','Insertion ID','Creative ID', 'key']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversion_date</th>\n",
       "      <th>Site-Offer ID</th>\n",
       "      <th>Insertion ID</th>\n",
       "      <th>Creative ID</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>1123</td>\n",
       "      <td>7485</td>\n",
       "      <td>1731</td>\n",
       "      <td>2016-03-10_1123_7485_1731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>1123</td>\n",
       "      <td>7485</td>\n",
       "      <td>1731</td>\n",
       "      <td>2016-03-10_1123_7485_1731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>1123</td>\n",
       "      <td>7485</td>\n",
       "      <td>1731</td>\n",
       "      <td>2016-03-10_1123_7485_1731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  conversion_date Site-Offer ID Insertion ID Creative ID  \\\n",
       "0      2016-03-10          1123         7485        1731   \n",
       "1      2016-03-10          1123         7485        1731   \n",
       "2      2016-03-10          1123         7485        1731   \n",
       "\n",
       "                         key  \n",
       "0  2016-03-10_1123_7485_1731  \n",
       "1  2016-03-10_1123_7485_1731  \n",
       "2  2016-03-10_1123_7485_1731  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailedConversions['key'] = np_concat(detailedConversions['conversion_date'], detailedConversions['Site-Offer ID'], detailedConversions['Insertion ID'], detailedConversions['Creative ID'])\n",
    "#QA the created key\n",
    "detailedConversions[['conversion_date','Site-Offer ID','Insertion ID','Creative ID', 'key']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's define several functions that'll be used for cleaning datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function aimed at cleaning revenue figures\n",
    "\n",
    "def cleanrev(col):\n",
    "    if col == '-':\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function aimed at cleaning products part of the orders\n",
    "\n",
    "def cleanGamme(col,gamme_prod):\n",
    "    items = list(set(col.split(\"|\")) )\n",
    "    if len(items) == 1:\n",
    "        return items[0]\n",
    "    elif re.search('|'.join(gamme_prod),col):\n",
    "        return \"Mixte\"\n",
    "    else:\n",
    "        return \"Mixte_non_comptabilise\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function aimed at associating products and unit price\n",
    "# /!\\ We need to verify every product are added and quantity matches\n",
    "\n",
    "def cleanProduitMix(df):\n",
    "    items = df[0].split(\"|\")\n",
    "    prices = df[1].split(\"|\")\n",
    "    quantity = df[2].split(\"|\")\n",
    "    if len(items) == 1:\n",
    "        return items[0] + '-%s' %float(prices[0]) #*float(quantity[0]))\n",
    "    else:\n",
    "#        mix = '%s-' %len(items)\n",
    "        l = len(items)\n",
    "        mix = ''\n",
    "        for i in range(0,len(items)-2):\n",
    "            mix = mix + items[i] + '-%s|' %float(prices[i]) #*float(quantity[i]))\n",
    "        return mix + items[l-1] + '-%s' %float(prices[l-1]) #*float(quantity[l-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#function aimed at concatenating several columns separated by '-'\n",
    "def concatenate(df):\n",
    "    if len(df)>0:\n",
    "        c = ''\n",
    "        l = len(df)-1\n",
    "        for i in range (0, l-1):\n",
    "            c = c + df[i] + '-'\n",
    "        return c + df[l]\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> The goal here is to agregate orders constituted by credited products to the 3PAS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "details3PAS = detailedConversions[['key','nom_site','gamme_produit', 'prix_produit','nombre_produit' ,'prix_ht_zanox']]\n",
    "details3PAS = pd.DataFrame(details3PAS).dropna()\n",
    "    \n",
    "details3PAS['revenue_transaction'] = details3PAS.prix_ht_zanox.apply(lambda x: cleanrev(x))\n",
    "details3PAS['panier'] = details3PAS.gamme_produit.apply(lambda x: cleanGamme(x,gamme_prod))\n",
    "\n",
    "#details3PAS.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#details3PAS[details3PAS.panier == 'Mixte'].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# /!\\  Section to be used once files are correctly populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reorder products with unit prices\n",
    "\n",
    "#http://stackoverflow.com/questions/13331698/how-to-apply-a-function-to-two-columns-of-pandas-dataframe\n",
    "#http://stackoverflow.com/questions/19914937/applying-function-with-multiple-arguments-to-create-a-new-pandas-column\n",
    "\n",
    "details3PAS['order'] = details3PAS[['gamme_produit','prix_produit','nombre_produit']].apply(cleanProduitMix, axis = 1)\n",
    "details3PAS = details3PAS.drop(['gamme_produit','nombre_produit','prix_produit','prix_ht_zanox'],1)\n",
    "\n",
    "#details3PAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It seems files are not accurately populated. \n",
    "# As basket details don't match actual basket (sum does not equals revenue transaction) we cannot use Mixed baskets\n",
    "\n",
    "\n",
    "#details3PAS[details3PAS.panier == 'Mixte'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> We need to create a row per product purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://stackoverflow.com/questions/17116814/pandas-how-do-i-split-text-in-a-column-into-multiple-rows\n",
    "#http://stackoverflow.com/questions/33622470/fast-way-to-split-column-into-multiple-rows-in-pandas\n",
    "\n",
    "s = details3PAS['order'].str.split(\"|\", expand=True).stack()\n",
    "i = s.index.get_level_values(0)\n",
    "df = details3PAS.loc[i].copy()\n",
    "df[\"order\"] = s.values\n",
    "\n",
    "\n",
    "#df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-9c4b9ff1182d>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-9c4b9ff1182d>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    c = np.append('key','item','unit_price'], axis = 0)\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['gamme_produit','prix_produit', 'prix_ht_zanox'], 1)\n",
    "\n",
    "s = df.order.apply(lambda x: pd.Series(x.split('-')))\n",
    "\n",
    "df = df.drop(['order'], 1)\n",
    "\n",
    "# prepare columns name for when we split order column\n",
    "c = df.columns.values\n",
    "c = np.append('key','item','unit_price'], axis = 0)\n",
    "\n",
    "df = df.join(s)\n",
    "df.columns =  c\n",
    "\n",
    "#df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> Performances summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# /!\\ filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key                    3647\n",
       "nom_site               3647\n",
       "gamme_produit          3647\n",
       "prix_produit           3647\n",
       "nombre_produit         3647\n",
       "prix_ht_zanox          3647\n",
       "revenue_transaction    3647\n",
       "panier                 3647\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details3PAS.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataSet3PAS= details3PAS.drop(['gamme_produit','nombre_produit','prix_produit','prix_ht_zanox'],1)\n",
    "#dataSet3PAS.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataSet3PAS = dataSet3PAS[dataSet3PAS.panier.isin(gamme_prod)]\n",
    "#dataSet3PAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transactions = dataSet3PAS.groupby(['key']).count()\n",
    "revenue = dataSet3PAS.groupby(['key']).sum()\n",
    "ds = pd.DataFrame(transactions,revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transactions = pd.DataFrame(dataSet3PAS.groupby([\"key\"]).sum()[\"revenue_transaction\"])\n",
    "revenue = pd.DataFrame(dataSet3PAS.groupby([\"key\"]).count()[\"panier\"])\n",
    "ds = transactions.join(revenue).reset_index()\n",
    "#c = np.append('key', 'revenue', 'conversions',axis =0)\n",
    "ds.columns = ['key', 'revenue', 'conversions']\n",
    "\n",
    "\n",
    "#ds.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dataSet3PAS[dataSet3PAS.key == '2016-03-10_1123_7485_1731']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ds[ds.key == '2016-03-10_1123_7485_1731']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_ds = pd.merge(adServerTable,ds, on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#final_ds[final_ds.key == '2016-03-10_1123_7485_1731'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_ds = final_ds[['Date', 'Site/Offer ID','Site/Offer', 'Insertion ID', 'Insertion', 'Creative ID', 'Creative', 'Creative Sizes','Imp.', 'Clicks','conversions', 'revenue', 'key' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#final_ds.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "final_ds.to_csv('3pas_report_final.csv', index=False,encoding='utf-8')\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
