{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns #pour faire des graph dans la bonne couleur etc.. par default\n",
    "import glob\n",
    "import re\n",
    "import csv as csv\n",
    "import random as rn\n",
    "import math\n",
    "import ast #http://stackoverflow.com/questions/1894269/convert-string-representation-of-list-to-list-in-python\n",
    "#import to_datetime\n",
    "import datetime\n",
    "from ggplot import *\n",
    "from __future__ import division\n",
    "\n",
    "#from lxml.html import parse\n",
    "from urllib2 import urlopen\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Upload datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Define products to be taken into account for credited conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">/!\\ Which products shall be taken into account?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://stackoverflow.com/questions/12096252/use-a-list-of-values-to-select-rows-from-a-pandas-dataframe\n",
    "gamme_prod = ['PD','DI','DN','TI','TN','AM','PR','GC','Mixte']\n",
    "\n",
    "\n",
    "cpm = 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Name of the files to be uploaded\n",
    "\n",
    "> These should be hosted in the root folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#file_quanti, 3PAS equivalent (Excel spreadsheet) \n",
    "adServerFile = 'Report_Quantcast_mobilite_Standard_v1_M88Z5cUHryFJpRP_AA1S.xlsx'\n",
    "#file_quali \n",
    "detailedFile = 'Report_Quantcast_mobilite_conversion_view_PNJjl0461vpIzpMgHrA7.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first file to be uploaded details of products part of each conversion. \n",
    "#We'll need to treat and refine this file so that only relevant products are being shown.\n",
    "detailedConversions = pd.read_csv(detailedFile, dtype=object)\n",
    "\n",
    "#We need to update the date format and strip hours\n",
    "#http://stackoverflow.com/questions/26387986/strip-time-from-an-object-date-in-pandas\n",
    "detailedConversions['conversion_date'] = pd.to_datetime(detailedConversions['Conversion date-hour'])\n",
    "detailedConversions['conversion_date'] = detailedConversions['conversion_date'].apply(lambda x:x.date().strftime('%Y-%m-%d'))\n",
    "\n",
    "#detailedConversions details products within each orders\n",
    "#check what's in detailedConversions\n",
    "#detailedConversions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#then upload the second file. this is the regular 3PAS files with every conversions to which we contributed. \n",
    "xls_file = pd.ExcelFile(adServerFile)\n",
    "adServerTable = xls_file.parse('DataView')\n",
    "\n",
    "#adServerTable credits each order to a vendor\n",
    "#check what's in adServerTable\n",
    "#adServerTable.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create matching key on both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create function that will be used to create matching key by concatenating several columns\n",
    "#http://stackoverflow.com/questions/23444858/concatenate-column-values-in-pandas-dataframe-with-nan-values\n",
    "def concat(*args):\n",
    "    strs = [str(arg) for arg in args if not pd.isnull(arg)]\n",
    "    return '_'.join(strs) if strs else np.nan\n",
    "\n",
    "np_concat = np.vectorize(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We need to define the key to join both file. \n",
    "#first 3PAS report Key - file_quanti\n",
    "adServerTable['key'] = np_concat(adServerTable['Date'], adServerTable['Site/Offer ID'], adServerTable['Insertion ID'], adServerTable['Creative ID'])\n",
    "#QA the created key\n",
    "#adServerTable[['Date','Site/Offer ID','Insertion ID','Creative ID', 'key']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Then file_quali\n",
    "detailedConversions['key'] = np_concat(detailedConversions['conversion_date'], detailedConversions['Site-Offer ID'], detailedConversions['Insertion ID'], detailedConversions['Creative ID'])\n",
    "#QA the created key\n",
    "#detailedConversions[['conversion_date','Site-Offer ID','Insertion ID','Creative ID', 'key']].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Both data sets have now corresponding matching key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Define functions for latter use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's define several functions that'll be used for cleaning datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function aimed at cleaning revenue figures\n",
    "\n",
    "def cleanrev(col):\n",
    "    if col == '-':\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function aimed at cleaning products part of the orders. \n",
    "#Distinguish monoproducts orders from ones with multiple products (ones with relevant products or non relevant product - as per the campaign)\n",
    "\n",
    "def cleanGamme(col,gamme_prod):\n",
    "    items = list(set(col.split(\"|\")) )\n",
    "    if len(items) == 1:\n",
    "        return items[0]\n",
    "    elif re.search('|'.join(gamme_prod),col):\n",
    "        return \"Mixte\"\n",
    "    else:\n",
    "        return \"Mixte_non_comptabilise\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function aimed at associating products and unit price\n",
    "# /!\\ We need to verify every product are added and quantity matches\n",
    "\n",
    "def cleanProduitMix(df):\n",
    "    items = df[0].split(\"|\")\n",
    "    prices = df[1].split(\"|\")\n",
    "    quantity = df[2].split(\"|\")\n",
    "    if len(items) == 1:\n",
    "        return items[0] + '-%s-%s' %(float(prices[0]), float(quantity[0]))\n",
    "    else:\n",
    "        l = len(items)\n",
    "        mix = ''\n",
    "        for i in range(0,len(items)-2):\n",
    "            mix = mix + items[i] + '-%s-%s|' %(float(prices[i]), float(quantity[i]))\n",
    "        return mix + items[l-1] + '-%s-%s' %(float(prices[l-1]), float(quantity[l-1]))\n",
    "\n",
    "#define the same function without tacking into account the quantity section    \n",
    "def cleanProduitMixWOQuantities(df):\n",
    "    items = df[0].split(\"|\")\n",
    "    prices = df[1].split(\"|\")\n",
    "    quantity = df[2].split(\"|\")\n",
    "    if len(items) == 1:\n",
    "        return items[0] + '-%s' %(float(prices[0]))\n",
    "    else:\n",
    "        l = len(items)\n",
    "        mix = ''\n",
    "        for i in range(0,len(items)-2):\n",
    "            mix = mix + items[i] + '-%s|' %(float(prices[i]))\n",
    "        return mix + items[l-1] + '-%s' %(float(prices[l-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#function aimed at concatenating several columns separated by '-'\n",
    "def concatenate(df):\n",
    "    if len(df)>0:\n",
    "        c = ''\n",
    "        l = len(df)-1\n",
    "        for i in range (0, l-1):\n",
    "            c = c + df[i] + '-'\n",
    "        return c + df[l]\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to be used when filtering out products not in required\n",
    "def filter_products(x):\n",
    "    if re.search('|'.join(gamme_prod),x):\n",
    "        return \"true\"\n",
    "    else:\n",
    "        return \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Treat and refine qualitative file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> The goal here is to:\n",
    "\n",
    ">> remove products not relevant for our media campign\n",
    "\n",
    ">>agregate orders constituted by credited products to the 3PAS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#select only relevant columns. remove NA.\n",
    "#you could use detailedConversions.count() to check what columns are part of the dataset \n",
    "details3PAS = detailedConversions[['key','nom_site','gamme_produit', 'prix_produit','nombre_produit' ,'prix_ht_zanox']]\n",
    "details3PAS = pd.DataFrame(details3PAS).dropna()\n",
    "\n",
    "#then clean revenue and order categories\n",
    "details3PAS['revenue_transaction'] = details3PAS.prix_ht_zanox.apply(lambda x: cleanrev(x))\n",
    "details3PAS['panier'] = details3PAS.gamme_produit.apply(lambda x: cleanGamme(x,gamme_prod))\n",
    "\n",
    "#details3PAS.head(4)\n",
    "#check the result for a given order ID (key)\n",
    "#details3PAS[details3PAS.key == '2016-04-08_1123_7485_1731'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first step with this qualitative dataset to count relevant conversions.\n",
    "#We need this first since we'll revamp the dataset to take into account only relevant revenu\n",
    "dataSet3PAS= details3PAS.drop(['gamme_produit','nombre_produit','prix_produit','prix_ht_zanox'],1)\n",
    "dataSet3PAS['selected'] = dataSet3PAS['panier'].apply(lambda x: filter_products(x))\n",
    "dataSet3PAS = dataSet3PAS[dataSet3PAS['selected'] == 'true']\n",
    "\n",
    "#get count of conversions relevant to us, this will be used later on when we'll aggregate datasets.\n",
    "transactions = dataSet3PAS.groupby(['key', 'nom_site']).agg({\n",
    "                                     'panier': 'count',\n",
    "                                     'revenue_transaction': sum\n",
    "                                               }).reset_index()    \n",
    "\n",
    "#rename columns and check results.\n",
    "transactions.columns = ['key', 'nom_site', 'relevant_conversions', 'total_revenue']\n",
    "#transactions.head(3)\n",
    "\n",
    "\n",
    "#transactions = dataSet3PAS.groupby(['key']).count().reset_index()\n",
    "#revenue = dataSet3PAS.groupby(['key']).sum().reset_index()\n",
    "#transactions.head(10)\n",
    "#revenue.head(10)\n",
    "#ds = transactions.join(revenue).reset_index()\n",
    "#ds.columns = ['key', 'revenue', 'conversions']\n",
    "#ds.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### /!\\ update cell below based on the structure of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#continue with the qualitative dataset, remove unnescessaries variables and apply function to filter out products\n",
    "#reorder products with unit prices\n",
    "#http://stackoverflow.com/questions/13331698/how-to-apply-a-function-to-two-columns-of-pandas-dataframe\n",
    "#http://stackoverflow.com/questions/19914937/applying-function-with-multiple-arguments-to-create-a-new-pandas-column\n",
    "\n",
    "## depending on the structure of the dataset use cleanProduitMix or cleanProduitMixWOQuantities (quantities being taken into account in the rveenue)\n",
    "#details3PAS['order'] = details3PAS[['gamme_produit','prix_produit','nombre_produit']].apply(cleanProduitMix, axis = 1)\n",
    "details3PAS['order'] = details3PAS[['gamme_produit','prix_produit','nombre_produit']].apply(cleanProduitMixWOQuantities, axis = 1)\n",
    "\n",
    "details3PAS = details3PAS.drop(['gamme_produit','nombre_produit','prix_produit','prix_ht_zanox'],1)\n",
    "\n",
    "#details3PAS.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Revenues don't always exactly match. \n",
    "\n",
    "> This might not be material (probably due to long strings stripped or VAT or shipping) but could worth checking with the customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> We now need to create a row per product purchased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://stackoverflow.com/questions/17116814/pandas-how-do-i-split-text-in-a-column-into-multiple-rows\n",
    "#http://stackoverflow.com/questions/33622470/fast-way-to-split-column-into-multiple-rows-in-pandas\n",
    "\n",
    "#create a column with only porduct and unit prices\n",
    "#we'll use stack function\n",
    "s = details3PAS['order'].str.split(\"|\", expand=True).stack() #.reset_index()\n",
    "i = s.index.get_level_values(0)\n",
    "df = details3PAS.loc[i].copy()\n",
    "df[\"order\"] = s.values\n",
    "#df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### /!\\ update cell below based on the structure of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_bis = df \n",
    "\n",
    "#make two columns out of this. might be tricky if we want to keep the original DF \n",
    "##Update based on the structure of the dataset use cleanProduitMix or cleanProduitMixWOQuantities\n",
    "#if cleanProduitMix function used\n",
    "#df_bis[\"product\"], df_bis[\"price\"], df_bis[\"quantity\"] = zip(*df_bis[\"order\"].str.split('-',2))\n",
    "#if cleanProduitMixWOQuantities function used\n",
    "df_bis[\"product\"], df_bis[\"price\"] = zip(*df_bis[\"order\"].str.split('-',1))\n",
    "\n",
    "\n",
    "df_bis[\"product\"] = df_bis[\"product\"].apply(lambda x: str(x))\n",
    "df_bis[\"price\"] = df_bis[\"price\"].apply(lambda x: float(x))\n",
    "\n",
    "##uncomment if quantity is being taken into account\n",
    "#df_bis[\"quantity\"] = df_bis[\"quantity\"].apply(lambda x: float(x))\n",
    "\n",
    "\n",
    "#df_bis[df_bis.key == '2016-03-14_1123_7491_1740'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### /!\\ update cell below based on the structure of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compute revenue for each product sold\n",
    "#uncomment the relevant line whether you take into account the quantity\n",
    "\n",
    "#df_bis['revenue_product'] = df_bis['price'] * df_bis['quantity']\n",
    "df_bis['revenue_product'] = df_bis['price'] * 1\n",
    "\n",
    "\n",
    "df_bis = df_bis[['key', 'nom_site', 'product', 'revenue_product']]\n",
    "#df_bis[df_bis.key == '2016-03-14_1123_7491_1740'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/var/localadmin/.conda/envs/py27/lib/python2.7/site-packages/IPython/kernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#keep only products concerned by our advertising campaign (products part of gamme_prod)\n",
    "\n",
    "df_final = df_bis\n",
    "#using our function defined above\n",
    "df_final[\"product_bis\"] = df_final[\"product\"].apply(lambda x: filter_products(x))\n",
    "\n",
    "#filtering out false products (products not concerned by the campaign)\n",
    "df_final = df_final[df_final['product_bis'] == \"true\"]\n",
    "#df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's sum valid revenue per transaction key (order ID, one revenue per order)\n",
    "# Group the data frame by month and item and extract a number of stats from each group\n",
    "\n",
    "df_final_bis = df_final.groupby(['key', 'nom_site']).agg({\n",
    "                                     'revenue_product':sum\n",
    "                                               }).reset_index()    \n",
    "\n",
    "#Add the total number conversions we stored in transactions DataFrame. We'll merge the two datasets.\n",
    "#transactions.columns = ['key', 'nom_site', 'relevant_conversions', 'total_revenue']\n",
    "#df_final_cleaned = pd.concat([df_final_bis,transactions], keys=['key'], join= 'inner' ,ignore_index=True)\n",
    "#df_final_cleaned = df_final_bis.append(transactions)\n",
    "df_final_cleaned = pd.merge(df_final_bis,transactions, how= 'inner', on = ['key', 'nom_site'] ,left_index=False,right_index=False)\n",
    "\n",
    "#df_final_cleaned.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> Performances summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# /!\\ filter dataset - first option not considered anymore since we computed revenue per product per transaction key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You may jump to the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#details3PAS.count()\n",
    "#details3PAS.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dataSet3PAS= details3PAS.drop(['gamme_produit','nombre_produit','prix_produit','prix_ht_zanox'],1)\n",
    "#dataSet3PAS.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dataSet3PAS = dataSet3PAS[dataSet3PAS.panier.isin(gamme_prod)]\n",
    "#dataSet3PAS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transactions = dataSet3PAS.groupby(['key']).count()\n",
    "#revenue = dataSet3PAS.groupby(['key']).sum()\n",
    "#ds = pd.DataFrame(transactions,revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transactions = pd.DataFrame(dataSet3PAS.groupby([\"key\"]).sum()[\"revenue_transaction\"])\n",
    "#revenue = pd.DataFrame(dataSet3PAS.groupby([\"key\"]).count()[\"panier\"])\n",
    "#ds = transactions.join(revenue).reset_index()\n",
    "#c = np.append('key', 'revenue', 'conversions',axis =0)\n",
    "#ds.columns = ['key', 'revenue', 'conversions']\n",
    "#ds.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dataSet3PAS[dataSet3PAS.key == '2016-03-10_1123_7485_1731']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ds[ds.key == '2016-03-10_1123_7485_1731']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Merge quantitative 3PAS report and qualitative report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> load quantitative 3PAS report and merge two files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#final_ds = pd.merge(adServerTable,ds, on='key')\n",
    "final_ds = pd.merge(adServerTable,df_final_cleaned, on='key')\n",
    "#final_ds[final_ds.key == '2016-03-10_1123_7485_1731'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#keep only relevant columns for reporting purpose\n",
    "final_ds = final_ds[['Date', 'Site/Offer ID','Site/Offer', 'Insertion ID', 'Insertion', 'Creative ID', 'Creative', 'Creative Sizes','Imp.', 'Clicks','relevant_conversions', 'revenue_product','total_revenue', 'key' ]]\n",
    "#final_ds.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add a few additional metrics such as cpa and roi\n",
    "#we first need the advertsier cost based on the cpm sold\n",
    "final_ds['cost'] = cpm * final_ds['Imp.'] / 1000\n",
    "#we can now compute cpa and ROI\n",
    "final_ds['cpa'] = final_ds['cost'] / final_ds['relevant_conversions']\n",
    "final_ds['roi'] = final_ds['revenue_product'] / final_ds['cost']\n",
    "\n",
    "#should you want to double check the results\n",
    "#final_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a CSV file that needs to be sent to campaign analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "final_ds.to_csv('3pas_report_final.csv', index=False,encoding='utf-8')\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
